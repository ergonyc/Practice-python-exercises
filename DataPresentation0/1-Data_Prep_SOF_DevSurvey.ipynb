{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter the warning for now on\n",
    "#import warnings\n",
    "#warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# new way to create an ordered category\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Description:\n",
    "\n",
    "The data set is the full, cleaned results of the 2019 Stack Overflow Developer Survey are in the external subdirectory. Free response submissions and personally identifying information have been removed from the results to protect the privacy of respondents. \n",
    "\n",
    "The survey was fielded from January 23 to February 14, 2019. The median time spent on the survey for qualified responses was 23.3 minutes.\n",
    "\n",
    "Respondents were recruited primarily through channels owned by Stack Overflow. The top 5 sources of respondents were onsite messaging, blog posts, email lists, Meta posts, banner ads, and social media posts. Since respondents were recruited in this way, highly engaged users on Stack Overflow were more likely to notice the links for the survey and click to begin it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## File Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three files:\n",
    "1. survey_results_public.csv - CSV file with main survey results, one respondent per row and one column per answer\n",
    "2. survey_results_schema.csv - CSV file with survey schema, i.e., the questions that correspond to each column name\n",
    "3. so_survey_2019.pdf - PDF file of survey instrument\n",
    "\n",
    "A local copy of survey_results_public.csv and survey_results_schema.csv were renamed survey2019.csv and schema2019.csv for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data if its not in the local directory\n",
    "\n",
    "if not os.path.exists(in_file):\n",
    "    # put these here in case we want to look at any other years...\n",
    "    url =  'https://drive.google.com/uc?export=download&id=1QOmVDpd8hcVYqqUXDXf68UMDWQZP0wQV'\n",
    "    survey_filename = 'survey_results_public.csv'\n",
    "    questions_filename = 'survey_results_schema.csv'\n",
    "    year = 2019\n",
    "    print('Downloading {} survey'.format(year))\n",
    "\n",
    "    request = requests.get(url)\n",
    "    with open('survey.zip', 'wb') as file:\n",
    "        file.write(request.content) \n",
    "\n",
    "    print('Unzipping {} survey'.format(year))\n",
    "    with zipfile.ZipFile(\"survey.zip\", \"r\") as file:\n",
    "        file.extractall(\"data/external/\")\n",
    "\n",
    "    print('Moving {} survey'.format(year))\n",
    "    shutil.copytree('data/external', 'data/raw')\n",
    "    shutil.copy('data/external/' + survey_filename, 'data/raw/survey{}.csv'.format(year))\n",
    "    shutil.copy('data/external/' + questions_filename, 'data/raw/schema{}.csv'.format(year))\n",
    "    \n",
    "    print('cleaning up')\n",
    "    os.remove('survey.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "in_file = Path.cwd() / \"data\" / \"raw\" / \"survey2019.csv\"\n",
    "# this is where our cleaned up file will put put\n",
    "summary_file = Path.cwd() / \"data\" / \"processed\" / f\"summary_{today:%b-%d-%Y}.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare the data\n",
    "\n",
    "- Remove all leading and trailing spaces (not nescessary)\n",
    "- Rename the columns for consistency (not nescessary)\n",
    "- Convert objects to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beware that the Respondent ids start at 1\n",
    "df = pd.read_csv(in_file, index_col='Respondent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MainBranch', 'Hobbyist', 'OpenSourcer', 'OpenSource', 'Employment',\n",
       "       'Country', 'Student', 'EdLevel', 'UndergradMajor', 'EduOther',\n",
       "       'OrgSize', 'DevType', 'YearsCode', 'Age1stCode', 'YearsCodePro',\n",
       "       'CareerSat', 'JobSat', 'MgrIdiot', 'MgrMoney', 'MgrWant', 'JobSeek',\n",
       "       'LastHireDate', 'LastInt', 'FizzBuzz', 'JobFactors', 'ResumeUpdate',\n",
       "       'CurrencySymbol', 'CurrencyDesc', 'CompTotal', 'CompFreq',\n",
       "       'ConvertedComp', 'WorkWeekHrs', 'WorkPlan', 'WorkChallenge',\n",
       "       'WorkRemote', 'WorkLoc', 'ImpSyn', 'CodeRev', 'CodeRevHrs', 'UnitTests',\n",
       "       'PurchaseHow', 'PurchaseWhat', 'LanguageWorkedWith',\n",
       "       'LanguageDesireNextYear', 'DatabaseWorkedWith',\n",
       "       'DatabaseDesireNextYear', 'PlatformWorkedWith',\n",
       "       'PlatformDesireNextYear', 'WebFrameWorkedWith',\n",
       "       'WebFrameDesireNextYear', 'MiscTechWorkedWith',\n",
       "       'MiscTechDesireNextYear', 'DevEnviron', 'OpSys', 'Containers',\n",
       "       'BlockchainOrg', 'BlockchainIs', 'BetterLife', 'ITperson', 'OffOn',\n",
       "       'SocialMedia', 'Extraversion', 'ScreenName', 'SOVisit1st',\n",
       "       'SOVisitFreq', 'SOVisitTo', 'SOFindAnswer', 'SOTimeSaved',\n",
       "       'SOHowMuchTime', 'SOAccount', 'SOPartFreq', 'SOJobs', 'EntTeams',\n",
       "       'SOComm', 'WelcomeChange', 'SONewContent', 'Age', 'Gender', 'Trans',\n",
       "       'Sexuality', 'Ethnicity', 'Dependents', 'SurveyLength', 'SurveyEase'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print column name\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero order sanity checks\n",
    "\n",
    "- column names\n",
    "- complete columns (no `nan`s)\n",
    "- look for highly unpopulated columns (nan > 50%)\n",
    "\n",
    "Check for empty entries...  complete columns... and columns with lots of missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    84.000000\n",
       "mean     13.780154\n",
       "std      12.171536\n",
       "min       0.000000\n",
       "25%       2.128078\n",
       "50%      10.792277\n",
       "75%      22.270007\n",
       "max      45.799534\n",
       "dtype: float64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what pct of of empty entries..\n",
    "(100 * df.isna().sum() / df.shape[0]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not too many holes in the data.\n",
    "\n",
    "How many complete columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hobbyist', 'OpenSourcer'}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns with no missing values\n",
    "set(df.isna().sum()[df.isna().sum()==0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which columns have over 50% missing values\n",
    "sum(df.columns[100*df.isna().sum()/df.shape[0] > 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create derived data columns\n",
    "\n",
    "- simplifications\n",
    "- summaries\n",
    "- multi-select splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert some columns to categorical\n",
    "\n",
    "- currently 'objects' containing strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only convert categories we want to convert... \n",
    "convert_to_cat = ['MainBranch', 'Hobbyist', 'OpenSourcer',  'Employment',\n",
    "       'Country', 'Student', 'UndergradMajor',\n",
    "       'OrgSize', 'DevType',\n",
    "       'CareerSat',  'MgrIdiot', 'MgrMoney', 'MgrWant', 'FizzBuzz',\n",
    "       'CurrencySymbol', 'CurrencyDesc', 'CompTotal', 'CompFreq', 'WorkWeekHrs', 'WorkPlan',\n",
    "       'WorkRemote', 'WorkLoc',  'CodeRev', 'CodeRevHrs', 'UnitTests',\n",
    "       'OpSys', 'BlockchainOrg', 'BlockchainIs', 'BetterLife', 'ITperson', 'OffOn',\n",
    "       'SocialMedia', 'Extraversion','Age', 'Gender', 'Trans',\n",
    "       'Sexuality', 'Ethnicity', 'Dependents', 'SurveyLength', 'SurveyEase','ScreenName']\n",
    "\n",
    "# convert to categories\n",
    "for col_name in convert_to_cat:\n",
    "    if(df[col_name].dtype == 'object'):\n",
    "        df[col_name] = df[col_name].astype('category')\n",
    "        #df[col_name] = df[col_name].cat.codes\n",
    "        \n",
    "# convert to ordered categories below\n",
    "#     'EdLevel','OpenSource','JobSat','ImpSyn',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert columns to ordered categories\n",
    "\n",
    "- eductaion level\n",
    "- openSource, career/job satisfaction\n",
    "- personal competence (ImpSyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered categories \n",
    "# Education\n",
    "edlevel_cat = CategoricalDtype( ['I never completed any formal education',\n",
    "                                 'Primary/elementary school',\n",
    "                                 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)',\n",
    "                                 'Some college/university study without earning a degree',\n",
    "                                 'Associate degree',\n",
    "                                 'Bachelor’s degree (BA, BS, B.Eng., etc.)',\n",
    "                                 'Master’s degree (MA, MS, M.Eng., MBA, etc.)',\n",
    "                                 'Professional degree (JD, MD, etc.)',\n",
    "                                 'Other doctoral degree (Ph.D, Ed.D., etc.)'],ordered=True)\n",
    "\n",
    "df['EdLevel'] = df.EdLevel.astype(edlevel_cat)\n",
    "\n",
    "#OpenSource . Higher, same lower\n",
    "opensource_cat = CategoricalDtype( ['OSS is, on average, of HIGHER quality than proprietary / closed source software',\n",
    "                                    'The quality of OSS and closed source software is about the same',\n",
    "                                    'OSS is, on average, of LOWER quality than proprietary / closed source software',], ordered=True)\n",
    "df['OpenSource'] = df.OpenSource.astype(opensource_cat)\n",
    " \n",
    "# career satisfaction / job satisfaction\\\n",
    "careersat_cat = CategoricalDtype(['Very dissatisfied',\n",
    "                                     'Slightly dissatisfied',\n",
    "                                     'Neither satisfied nor dissatisfied',\n",
    "                                     'Slightly satisfied',\n",
    "                                     'Very satisfied'], ordered=True)\n",
    "df['CareerSat'] = df.CareerSat.astype(careersat_cat)\n",
    "\n",
    "jobsat_cat = CategoricalDtype(['Very dissatisfied',\n",
    "                                     'Slightly dissatisfied',\n",
    "                                     'Neither satisfied nor dissatisfied',\n",
    "                                     'Slightly satisfied',\n",
    "                                     'Very satisfied'], ordered=True)\n",
    "df['JobSat'] = df.JobSat.astype(jobsat_cat)\n",
    "\n",
    "#competence\n",
    "impsyn_cat = CategoricalDtype( ['Far below average',\n",
    "                                 'A little below average',\n",
    "                                 'Average',\n",
    "                                 'A little above average',\n",
    "                                 'Far above average'], ordered=True)\n",
    "df['ImpSyn']  = df.ImpSyn.astype(impsyn_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 88883 rows and 86 columns.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset contains', df.shape[0], 'rows and', df.shape[1], 'columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create derived data columns\n",
    "\n",
    "- Simplify some categories\n",
    "    - Education: Advanced, College, Grade\n",
    "    - Major: Computer/Tech, Math/Science, Other\n",
    "        \n",
    "- generation (from Age)\n",
    "   - Age->Gen: GenZ,Milennial,GenX,Boomer,Silent\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 88883 rows and 86 columns.\n"
     ]
    }
   ],
   "source": [
    "# Print shape of dataset\n",
    "#print('The dataset contains', np.shape(df)[0], 'rows and', np.shape(df)[1], 'columns.')\n",
    "print('The dataset contains', df.shape[0], 'rows and', df.shape[1], 'columns.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['I never completed any formal education', 'Primary/elementary school',\n",
       "       'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)',\n",
       "       'Some college/university study without earning a degree',\n",
       "       'Associate degree', 'Bachelor’s degree (BA, BS, B.Eng., etc.)',\n",
       "       'Master’s degree (MA, MS, M.Eng., MBA, etc.)',\n",
       "       'Professional degree (JD, MD, etc.)',\n",
       "       'Other doctoral degree (Ph.D, Ed.D., etc.)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EdLevel'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 23199 respondents with advanced degrees, (n= 52574 college; n= 10617 grade)  88883 og~ 88883 null-> 2493\n"
     ]
    }
   ],
   "source": [
    "# old method comparing strings\n",
    "\n",
    "advanced = df['EdLevel'].isin(['Other doctoral degree (Ph.D, Ed.D., etc.)',\n",
    "                               'Master’s degree (MA, MS, M.Eng., MBA, etc.)',\n",
    "                               'Professional degree (JD, MD, etc.)'])\n",
    "\n",
    "college = df['EdLevel'].isin(['Associate degree',\n",
    "                              'Bachelor’s degree (BA, BS, B.Eng., etc.)',\n",
    "                              'Some college/university study without earning a degree'])\n",
    "\n",
    "grade = df['EdLevel'].isin(['Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)',\n",
    "                            'Primary/elementary school',\n",
    "                            'I never completed any formal education'])\n",
    "no_answer = df['EdLevel'].isnull()\n",
    "\n",
    "print('The dataset contains',  advanced.sum(),\n",
    "      'respondents with advanced degrees, (n=', college.sum(),\n",
    "      'college; n=', grade.sum(), 'grade) ', (advanced.sum() +\n",
    "                                              college.sum()+grade.sum()+no_answer.sum()),\n",
    "      'og~', df.shape[0],\n",
    "      'null->', no_answer.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ordered category\n",
    "edlevel_simple_cat = CategoricalDtype(  ['Grade',\n",
    "                                 'College', #'N/A'\n",
    "                                 'Advanced'], ordered=True)\n",
    "df.loc[:,'Education'] = np.nan\n",
    "\n",
    "df.loc[advanced,'Education'] = 'Advanced'\n",
    "df.loc[college,'Education'] = 'College'\n",
    "df.loc[grade,'Education'] = 'Grade'\n",
    "#df.loc[no_answer,'Education'] = 'N/A'\n",
    "#df.loc[:,'Education'] = np.nan\n",
    "# now make it an ordered category\n",
    "df.loc[:,'Education']  = df.Education.astype(edlevel_simple_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #method using ordered category (is awkward because of nan)\n",
    "# if False:\n",
    "#     advanced = (survey['EdLevel'].dropna() >= survey.EdLevel.cat.categories[6])\n",
    "\n",
    "#     college = ((survey['EdLevel'].dropna() < survey.EdLevel.cat.categories[6]) & (survey['EdLevel'].dropna() >= survey.EdLevel.cat.categories[3])) \n",
    "  \n",
    "#     grade = (survey['EdLevel'].dropna() < survey.EdLevel.cat.categories[3])\n",
    "#     no_answer = survey['EdLevel'].isnull()\n",
    "\n",
    "    \n",
    "#     print('The dataset contains',  advanced.sum(),  \n",
    "#           'respondents with advanced degrees, (n=', college.sum(), \n",
    "#           'college; n=', grade.sum(), 'grade) ', (advanced.sum()+college.sum()+grade.sum()+no_answer.sum() ),\n",
    "#          'og~',survey.shape[0], \n",
    "#          'null->', no_answer.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "1      Grade\n",
       "2      Grade\n",
       "3    College\n",
       "Name: Education, dtype: category\n",
       "Categories (3, object): [Grade < College < Advanced]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Education'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Major'] = np.nan   \n",
    "\n",
    "computer_tech = df['UndergradMajor'].isin(['Computer science, computer engineering, or software engineering',\n",
    "                                        'Web development or web design',\n",
    "                                        'Information systems, information technology, or system administration'])\n",
    "   \n",
    "\n",
    "math_sci = df['UndergradMajor'].isin(['Mathematics or statistics',\n",
    "                                          'Another engineering discipline (ex. civil, electrical, mechanical)',\n",
    "                                          'A natural science (ex. biology, chemistry, physics)'])\n",
    "       \n",
    "other = df['UndergradMajor'].isin(['A health science (ex. nursing, pharmacy, radiology)',\n",
    "                                       'A business discipline (ex. accounting, finance, marketing)',\n",
    "                                       'A humanities discipline (ex. literature, history, philosophy)',\n",
    "                                       'A social science (ex. anthropology, psychology, political science)',\n",
    "                                       'Fine arts or performing arts (ex. graphic design, music, studio art)'])\n",
    " \n",
    "\n",
    "df.loc[computer_tech,'Major'] = 'Computer/Tech'\n",
    "df.loc[math_sci,'Major'] = 'Math/Science'\n",
    "df.loc[other,'Major'] = 'Other'\n",
    "#df.loc[no_answer,'EdLevel_simple'] = 'N/A'\n",
    "\n",
    "df.loc[:,'Major']  = df.Major.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "1              NaN\n",
       "2              NaN\n",
       "3    Computer/Tech\n",
       "4    Computer/Tech\n",
       "5    Computer/Tech\n",
       "Name: Major, dtype: category\n",
       "Categories (3, object): [Computer/Tech, Math/Science, Other]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Major'].head()\n",
    "#survey.UndergradMajor.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix some nonsensical numbers\n",
    "\n",
    "---\n",
    "Age: `Age`-> `nAge`  change < 13, or > 80 to `NaN`\n",
    "1st Code: `Age1stCode` -> `nAgeCode` , change \"Younger than 5 years\" to 4.5 and \"Older than 85\" to 85.\n",
    "years coding, years experience: `YearsCode` -> `nYearsCode`, change \"Less than 1 year\" to 1/10000 and \"More than 50\" to 55.\n",
    "years pro:`YearsCodePro` -> `nYearsPro`\n",
    "workweek: `WorkWeekHrs` to require 4 hours off per day\n",
    "\n",
    "---\n",
    "Test that `ConvertedComp` is sensible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_years_coding(years_):\n",
    "    # make these numeric in a sensible way\n",
    "    if years_ == 'Less than 1 year':\n",
    "        return 0.0001\n",
    "    elif years_ == 'More than 50 years':\n",
    "        return 55.\n",
    "    else:\n",
    "        return years_\n",
    "\n",
    "    \n",
    "def fix_age(years_):\n",
    "    # make these numeric in a sensible way  exclude pre-teens and aged >84\n",
    "    if years_ < 13:\n",
    "        return np.NaN\n",
    "    elif years_ > 84:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return years_ \n",
    "    \n",
    "def fix_age1stcode(years_):\n",
    "    if years_ == 'Younger than 5 years':\n",
    "        return 4.5\n",
    "    elif years_ == 'Older than 85':\n",
    "        return 85.\n",
    "    else:\n",
    "        return years_\n",
    "\n",
    "\n",
    "def fix_workweekhours(hours_):\n",
    "    #if hours_ == np.NaN:\n",
    "    #    return hours_\n",
    "    if hours_ > 20*7:  # hard ceiling on hours in a week (24*7)  lets throw out the ridiculous no sleep 24/7 scenarios\n",
    "        return np.NaN\n",
    "    elif hours_ < 4: # arbitrary minimum work time\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return hours_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'nYearsCode'] =  pd.to_numeric(df.YearsCode.apply(fix_years_coding))\n",
    "df.loc[:,'nYearsPro'] = pd.to_numeric(df.YearsCodePro.apply(fix_years_coding))\n",
    "df.loc[:,'WorkWeekH'] = df.WorkWeekHrs.apply(fix_workweekhours)\n",
    "df.loc[:,'nAge'] =  pd.to_numeric(df.Age.apply(fix_age))\n",
    "df.loc[:,'nAgeCode'] =  pd.to_numeric(df.Age1stCode.apply(fix_age1stcode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    79210.000000\n",
       "mean        30.336699\n",
       "std          9.178390\n",
       "min          1.000000\n",
       "25%         24.000000\n",
       "50%         29.000000\n",
       "75%         35.000000\n",
       "max         99.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    64017.000000\n",
       "mean        40.376339\n",
       "std         10.092518\n",
       "min          4.000000\n",
       "25%         40.000000\n",
       "50%         40.000000\n",
       "75%         44.000000\n",
       "max        140.000000\n",
       "Name: WorkWeekH, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['WorkWeekH'].dropna().describe()\n",
    "# looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>21803</td>\n",
       "      <td>127388.806816</td>\n",
       "      <td>61872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>32559</td>\n",
       "      <td>127992.870788</td>\n",
       "      <td>54996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count           mean   median\n",
       "Dependents                               \n",
       "Yes         21803  127388.806816  61872.0\n",
       "No          32559  127992.870788  54996.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Dependents').ConvertedComp.agg(['count','mean','median']).sort_values('mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Categorize according to standard \"generations\"\n",
    "\n",
    "- Gen Z\n",
    "- Millenial\n",
    "- Gen X\n",
    "- Boomers\n",
    "- Silent\n",
    "\n",
    "![alt text][logo]\n",
    "\n",
    "[logo]:\n",
    "https://www.pewresearch.org/wp-content/uploads/2019/01/FT_19.01.17_generations_2019.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Age to generation with 2019 as current time reference\n",
    "def find_gen(age):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if age <= 22:\n",
    "        gen = 'GenZ'\n",
    "        return gen\n",
    "    elif age <= 38:\n",
    "        gen = 'Millenial'\n",
    "    elif age <= 54:\n",
    "        gen = 'GenX'\n",
    "    elif age <= 73:\n",
    "        gen = 'Boomer'\n",
    "    else:\n",
    "        gen = 'Silent'\n",
    "    return gen\n",
    "\n",
    "\n",
    "generation_cat = CategoricalDtype(['GenZ',\n",
    "                                   'Millenial',\n",
    "                                   'GenX',\n",
    "                                   'Boomer',\n",
    "                                   'Silent',  # 'N/A'\n",
    "                                   ], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gen</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GenZ</th>\n",
       "      <td>3874</td>\n",
       "      <td>67796.219411</td>\n",
       "      <td>19266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Millenial</th>\n",
       "      <td>40895</td>\n",
       "      <td>121602.788654</td>\n",
       "      <td>53500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silent</th>\n",
       "      <td>2324</td>\n",
       "      <td>138549.665232</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenX</th>\n",
       "      <td>7756</td>\n",
       "      <td>172946.333935</td>\n",
       "      <td>91660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boomer</th>\n",
       "      <td>974</td>\n",
       "      <td>202005.099589</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count           mean    median\n",
       "Gen                                      \n",
       "GenZ        3874   67796.219411   19266.0\n",
       "Millenial  40895  121602.788654   53500.0\n",
       "Silent      2324  138549.665232   60000.0\n",
       "GenX        7756  172946.333935   91660.0\n",
       "Boomer       974  202005.099589  110000.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to subsets\n",
    "df.loc[:,'Gen'] = np.nan\n",
    "df.loc[:,'Gen'] = df.Age.apply(find_gen).copy()\n",
    "df.loc[:,'Gen']  = df.Gen.astype(generation_cat)\n",
    "df.groupby('Gen').ConvertedComp.agg(['count','mean','median']).sort_values('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EduOther                  object\n",
       "YearsCode                 object\n",
       "Age1stCode                object\n",
       "YearsCodePro              object\n",
       "JobSeek                   object\n",
       "LastHireDate              object\n",
       "LastInt                   object\n",
       "JobFactors                object\n",
       "ResumeUpdate              object\n",
       "WorkChallenge             object\n",
       "PurchaseHow               object\n",
       "PurchaseWhat              object\n",
       "LanguageWorkedWith        object\n",
       "LanguageDesireNextYear    object\n",
       "DatabaseWorkedWith        object\n",
       "DatabaseDesireNextYear    object\n",
       "PlatformWorkedWith        object\n",
       "PlatformDesireNextYear    object\n",
       "WebFrameWorkedWith        object\n",
       "WebFrameDesireNextYear    object\n",
       "MiscTechWorkedWith        object\n",
       "MiscTechDesireNextYear    object\n",
       "DevEnviron                object\n",
       "Containers                object\n",
       "SOVisit1st                object\n",
       "SOVisitFreq               object\n",
       "SOVisitTo                 object\n",
       "SOFindAnswer              object\n",
       "SOTimeSaved               object\n",
       "SOHowMuchTime             object\n",
       "SOAccount                 object\n",
       "SOPartFreq                object\n",
       "SOJobs                    object\n",
       "EntTeams                  object\n",
       "SOComm                    object\n",
       "WelcomeChange             object\n",
       "SONewContent              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these will need to be \"split\" later\n",
    "treat_as_lists = ['JobFactors','DevEnviron',\n",
    "                 'Containers','WorkChallenge',\n",
    "                 'LanguageWorkedWith', 'LanguageDesireNextYear', \n",
    "                 'DatabaseWorkedWith','DatabaseDesireNextYear', \n",
    "                 'MiscTechWorkedWith','MiscTechDesireNextYear', \n",
    "                 'EduOther']\n",
    "df.dtypes[df.dtypes==('object')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Clean Data\n",
    "\n",
    "### Respondent Cleanup\n",
    "\n",
    "- KEEP PROFESSIONALS ONLY.  Dropped students and \"other\"\n",
    "- Create our categories of respondents (aux columns)\n",
    "    - DataScientist\n",
    "    - Non-DataScientists (everybody else, including un-engaged, jokers, and students)\n",
    "    - Developers (other \"professionals\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I am a student who is learning to code, I am not primarily a developer, but I write co..., I am a developer by profession, I code primarily as a hobby, I used to be a developer by profession, but no..., NaN]\n",
       "Categories (5, object): [I am a student who is learning to code, I am not primarily a developer, but I write co..., I am a developer by profession, I code primarily as a hobby, I used to be a developer by profession, but no...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MainBranch'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are interested in comparing data scientists to non-data scientists, we need to be able to differentiate between the two. This is done using the `DevType` field. As a result, we should drop any rows where this field is missing, since we can't determine which subset these rows fit into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some of the categories ordered\n",
    "developers = df['MainBranch'] == 'I am a developer by profession' # df['MainBranch'].cat.categories[0]\n",
    "# limit our scope to professional developers\n",
    "df = df[developers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 65679 rows and 92 columns.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset contains', df.shape[0], 'rows and', df.shape[1], 'columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data scientist and non-data scientist subsets.\n",
    "# data scientists are defined as \"Data or business analyst\",Engineer, Data\", \"Data scientist or machine learning specialist\"\n",
    "# Database administrator or Scientist\n",
    "\n",
    "# developer is \"Developer, {fullstack, game or graphics, mobile, QA or test}\"\n",
    "data_scientist = df['DevType'].str.contains('|'.join(['data','scientist']), case=False, na=False, regex=True).copy() #data scientists / analists / Data engineers\n",
    "\n",
    "#data = df['DevType'].str.contains('data', case=False, na=False, regex=True).copy() #data scientists / analists / Data engineers\n",
    "developer = df['DevType'].str.contains('developer', case=False, na=False,regex=True).copy() #all types of developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database administrator;Developer, back-end;Dev..., Data or business analyst;Data scientist or mac..., Data or business analyst;Database administrato..., Data or business analyst;Designer;Developer, b..., Academic researcher;Data scientist or machine ..., ..., Developer, back-end;Developer, desktop or ente..., Data scientist or machine learning specialist;..., Data scientist or machine learning specialist;..., Data scientist or machine learning specialist;..., Academic researcher;Database administrator;Dev...]\n",
       "Length: 6805\n",
       "Categories (6805, object): [Database administrator;Developer, back-end;Dev..., Data or business analyst;Data scientist or mac..., Data or business analyst;Database administrato..., Data or business analyst;Designer;Developer, b..., ..., Data scientist or machine learning specialist;..., Data scientist or machine learning specialist;..., Data scientist or machine learning specialist;..., Academic researcher;Database administrator;Dev...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# its way too messy to parse through the multi-selects... \n",
    "df.DevType[data_scientist].unique()\n",
    "#df.DevType[developer].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15151"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scientist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some expository columns\n",
    "df.loc[:,'DSorDV'] = np.nan\n",
    "\n",
    "df.loc[data_scientist,'DSorDV'] = 'Data Scientist'\n",
    "df.loc[developer,'DSorDV'] = 'Developer'\n",
    "\n",
    "df.loc[:,'isDS'] = data_scientist\n",
    "df.loc[:,'isDev'] = developer\n",
    "df.loc[:,'notDS'] = ~data_scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Cleanup\n",
    "- Drop columns which we don't want to anlayze\n",
    "- re-order/group columns (in case we want to select with slices?)\n",
    "- Remove all leading and trailing spaces (not nescessary)\n",
    "- Rename the columns for consistency (not nescessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MainBranch', 'Hobbyist', 'OpenSourcer', 'OpenSource', 'Employment',\n",
       "       'Country', 'Student', 'EdLevel', 'UndergradMajor', 'EduOther',\n",
       "       'OrgSize', 'DevType', 'YearsCode', 'Age1stCode', 'YearsCodePro',\n",
       "       'CareerSat', 'JobSat', 'MgrIdiot', 'MgrMoney', 'MgrWant', 'JobSeek',\n",
       "       'LastHireDate', 'LastInt', 'FizzBuzz', 'JobFactors', 'ResumeUpdate',\n",
       "       'CurrencySymbol', 'CurrencyDesc', 'CompTotal', 'CompFreq',\n",
       "       'ConvertedComp', 'WorkWeekHrs', 'WorkPlan', 'WorkChallenge',\n",
       "       'WorkRemote', 'WorkLoc', 'ImpSyn', 'CodeRev', 'CodeRevHrs', 'UnitTests',\n",
       "       'PurchaseHow', 'PurchaseWhat', 'LanguageWorkedWith',\n",
       "       'LanguageDesireNextYear', 'DatabaseWorkedWith',\n",
       "       'DatabaseDesireNextYear', 'PlatformWorkedWith',\n",
       "       'PlatformDesireNextYear', 'WebFrameWorkedWith',\n",
       "       'WebFrameDesireNextYear', 'MiscTechWorkedWith',\n",
       "       'MiscTechDesireNextYear', 'DevEnviron', 'OpSys', 'Containers',\n",
       "       'BlockchainOrg', 'BlockchainIs', 'BetterLife', 'ITperson', 'OffOn',\n",
       "       'SocialMedia', 'Extraversion', 'ScreenName', 'SOVisit1st',\n",
       "       'SOVisitFreq', 'SOVisitTo', 'SOFindAnswer', 'SOTimeSaved',\n",
       "       'SOHowMuchTime', 'SOAccount', 'SOPartFreq', 'SOJobs', 'EntTeams',\n",
       "       'SOComm', 'WelcomeChange', 'SONewContent', 'Age', 'Gender', 'Trans',\n",
       "       'Sexuality', 'Ethnicity', 'Dependents', 'SurveyLength', 'SurveyEase',\n",
       "       'Education', 'Major', 'nYearsCode', 'nYearsPro', 'WorkWeekH', 'nAge',\n",
       "       'nAgeCode', 'Gen', 'DSorDV', 'isDS', 'isDev', 'notDS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['Education', 'Major', 'nYearsCode','nAgeCode','nAge'\n",
    "               'nYearsPro', 'WorkWeekH', 'Gen', 'isDS', 'isDev', 'notDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "keep_columns = [\n",
    "        'MainBranch',  # should be only Developers so could drop\n",
    "        #\n",
    "        'Employment',\n",
    "        'Country',\n",
    "        'Student',\n",
    "        #\n",
    "        'EdLevel',\n",
    "        'UndergradMajor',\n",
    "        'Major',\n",
    "        'Education',\n",
    "        #\n",
    "        'OrgSize',\n",
    "        'DevType',\n",
    "        'isDS', 'isDev', 'notDS', 'DSorDV',\n",
    "        # Years  -treat as numbers\n",
    "        'nYearsCode',  # 'YearsCode',\n",
    "        'nYearsPro',  # 'YearsCodePro',\n",
    "        'nAgeCode',  # 'Age1stCide'\n",
    "        'WorkWeekH',  # 'WorkWeekHrs'\n",
    "        #\n",
    "        'ImpSyn',  # PRIMARY  # Self - competence !!!\n",
    "        'CareerSat',\n",
    "        'JobSat',\n",
    "        'MgrIdiot',  # MGR competence\n",
    "        'MgrMoney',  # do you need to be a manager to make $$\n",
    "        'MgrWant',  # do you want to be a manager\n",
    "        # 'JobFactors', # what drives values - grouped with other list types below\n",
    "        'ConvertedComp',  # PRIMARY\n",
    "        #\n",
    "        'OpenSourcer',\n",
    "        'OpenSource',\n",
    "        #\n",
    "        'OpSys',\n",
    "        'BlockchainOrg', 'BlockchainIs',\n",
    "        # personality\n",
    "        'BetterLife',\n",
    "        'ITperson', 'OffOn',\n",
    "        #  social / demographic\n",
    "        'SocialMedia',\n",
    "        'Extraversion',\n",
    "        'ScreenName',\n",
    "        'nAge', 'Gen',\n",
    "        'Gender', 'Trans',\n",
    "        'Sexuality', 'Ethnicity', 'Dependents',\n",
    "        # do these pairs  helps is understand how they see the future? (maybe drop)\n",
    "        'JobFactors', 'DevEnviron',\n",
    "        'Containers', 'WorkChallenge',\n",
    "        'LanguageWorkedWith', 'LanguageDesireNextYear',\n",
    "        'DatabaseWorkedWith', 'DatabaseDesireNextYear',\n",
    "        'MiscTechWorkedWith', 'MiscTechDesireNextYear',\n",
    "        'PlatformWorkedWith', 'PlatformDesireNextYear',\n",
    "        'EduOther',\n",
    "        # might want to look at these later.\n",
    "        'Hobbyist',\n",
    "        'FizzBuzz',\n",
    "        'ResumeUpdate',\n",
    "        'CurrencySymbol', 'CurrencyDesc',\n",
    "        'CompTotal', 'CompFreq',\n",
    "        'SurveyLength', 'SurveyEase']\n",
    "\n",
    "\n",
    "df = df[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset now contains 65679 rows and 65 columns.\n"
     ]
    }
   ],
   "source": [
    "# SKIP ALL STACKOVERFLOW PARTICULARS\n",
    "#'JobSeek','LastHireDate', 'LastInt',\n",
    "#'WorkPlan', 'WorkChallenge',\n",
    "#' WorkRemote', 'WorkLoc',\n",
    "#'CodeRev', 'CodeRevHrs', 'UnitTests',\n",
    "#'PurchaseHow', 'PurchaseWhat',\n",
    "# Skip these\n",
    "# 'WebFrameWorkedWith','WebFrameDesireNextYear',\n",
    "# Print shape of dataset\n",
    "print('The dataset now contains',\n",
    "      df.shape[0], 'rows and', df.shape[1], 'columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Finalized Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_to_rename = {'col1': 'New_Name'}\n",
    "#df.rename(columns=cols_to_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some categories if nescessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output file into processed directory\n",
    "\n",
    "Save a file in the processed directory that is cleaned properly. It will be read in and used later for further analysis.\n",
    "\n",
    "Other options besides pickle include:\n",
    "- feather\n",
    "- msgpack\n",
    "- parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ergonyc/Projects/Insight/Modules/DataPresentation0/data/processed/summary_Sep-04-2019.pkl')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_pickle(summary_file)\n",
    "\n",
    "summary_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create categories of respondents t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Split Multi-Selection Fields\n",
    "\n",
    "\n",
    "For the fields where multiple selections were possible (e.g.  `JobFactors`,`DevEnviron`, and `LanguageWorkedWith`), split the strings containing the multiple selections into a list of selections and then concatenate these lists into a single list (dropping any missing values in the process). \n",
    "\n",
    "We may also want to simplify these fields to reduce the length of category labels and to group similar categories into a single category apon further analysis.\n",
    "\n",
    "Full list of the multi-select variables we will be addressing:\n",
    " `JobFactors`,`DevEnviron`,`Containers`,`WorkChallenge`, as well as the current/future pairs:\n",
    "     `LanguageWorkedWith`, `LanguageDesireNextYear`, \n",
    "     `DatabaseWorkedWith`,`DatabaseDesireNextYear`, \n",
    "     `MiscTechWorkedWith`,`MiscTechDesireNextYear`, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languages \n",
    "\n",
    "`LanguageWorkedWith`, `LanguageDesireNextYear`, \n",
    "\n",
    "Should I convert these to categories?  maybe I should just prepare then, but not break into boolean fields until analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#languages_full = survey['LanguageWorkedWith'].dropna().str.split(';').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript               46945\n",
       "HTML/CSS                 41911\n",
       "SQL                      37235\n",
       "Java                     26348\n",
       "Python                   24285\n",
       "Bash/Shell/PowerShell    24195\n",
       "C#                       21657\n",
       "PHP                      17042\n",
       "TypeScript               16535\n",
       "C++                      13296\n",
       "C                        11130\n",
       "Ruby                      5923\n",
       "Go                        5852\n",
       "Other(s):                 5596\n",
       "Swift                     4652\n",
       "Kotlin                    4590\n",
       "Objective-C               3615\n",
       "Assembly                  3173\n",
       "VBA                       2987\n",
       "Scala                     2805\n",
       "R                         2731\n",
       "Rust                      1981\n",
       "Dart                      1244\n",
       "Elixir                    1064\n",
       "Clojure                   1029\n",
       "F#                         757\n",
       "WebAssembly                745\n",
       "Erlang                     622\n",
       "nan                        405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have to split the LanguageWorkedWith to get a proper picture\n",
    "#languages = survey[survey['LanguageWorkedWith'].notnull()]\n",
    "\n",
    "col = 'LanguageWorkedWith' \n",
    "\n",
    "unique_selects = {}\n",
    "\n",
    "select_na = df[col].isnull()\n",
    "# split the languages on ;\n",
    "#for language_set in survey['LanguageWorkedWith'].dropna().apply(lambda row: str(row).split(';')) :\n",
    "for select_set in df[col].apply(lambda row: str(row).split(';')) :\n",
    "    for select in select_set:\n",
    "        if select not in unique_selects.keys():\n",
    "            unique_selects[select] = 1\n",
    "        else:\n",
    "            unique_selects[select] += 1\n",
    "            \n",
    "un_sel = pd.Series(unique_selects).sort_values(ascending=False).copy()\n",
    "#un_sel.index == 'nan'\n",
    "un_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['JavaScript', 'HTML/CSS', 'SQL', 'Java', 'Python',\n",
       "       'Bash/Shell/PowerShell', 'C#', 'PHP', 'TypeScript', 'C++', 'C', 'Ruby',\n",
       "       'Go', 'Other(s):', 'Swift', 'Kotlin', 'Objective-C', 'Assembly', 'VBA',\n",
       "       'Scala', 'R', 'Rust', 'Dart', 'Elixir', 'Clojure', 'F#', 'WebAssembly',\n",
       "       'Erlang', 'nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df = pd.DataFrame() #columns = unique_selects)\n",
    "\n",
    "prefix = col[:20]\n",
    "un_sel.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65679,)\n",
      "(65679, 29)\n"
     ]
    }
   ],
   "source": [
    "for sel in un_sel.index:\n",
    "    col_name = col + sel.replace(' ','_')\n",
    "    if (sel == 'nan'):\n",
    "        out_df.loc[:,col_name] = select_na\n",
    "\n",
    "    else:\n",
    "        out_df.loc[:,col_name] = ~select_na\n",
    "        selected = df[col].dropna().str.split(';').copy() #.tolist()\n",
    "        # need to strip the nulls\n",
    "        out_df.loc[~select_na,col_name] = selected.apply(lambda x: sel in x)\n",
    "        out_df.loc[select_na,col_name] = np.nan\n",
    "\n",
    "        \n",
    "print(select_na.shape)\n",
    "print(out_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.029765983038718"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100*out_df.sum().sort_values(ascending=False)/out_df.shape[0])\n",
    "\n",
    "numLang = out_df.sum(axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to split the LanguageWorkedWith to get a proper picture\n",
    "#languages = survey[survey['LanguageWorkedWith'].notnull()] \n",
    "def split_multiselect(df, col):\n",
    "    \"\"\"Create a new dataframe that splits the values of multi-selection column col into individual selections and \n",
    "    places each selection into a boolean column. This new dataframe can be merged into the original dataframe by \n",
    "    Respondent (index)value.\n",
    "    \n",
    "    Args:\n",
    "    df: dataframe. Dataframe containing the multi-selection field col.\n",
    "    col:  column name\n",
    "    \n",
    "    Returns:\n",
    "    out_df: dataframe. New dataframe giving split values of col.\n",
    "        \"\"\"\n",
    "\n",
    "    unique_selects = {}\n",
    "\n",
    "    select_na = df[col].isnull()\n",
    "    # split the languages on ;\n",
    "    #for language_set in survey['LanguageWorkedWith'].dropna().apply(lambda row: str(row).split(';')) :\n",
    "    for select_set in df[col].apply(lambda row: str(row).split(';')) :\n",
    "        for select in select_set:\n",
    "            if select not in unique_selects.keys():\n",
    "                unique_selects[select] = 1\n",
    "            else:\n",
    "                unique_selects[select] += 1\n",
    "\n",
    "    un_sel = pd.Series(unique_selects).sort_values(ascending=False).copy()\n",
    "    #un_sel.index == 'nan'\n",
    "    out_df = pd.DataFrame() #columns = unique_selects)\n",
    "    new_cols = []\n",
    "    for sel in un_sel.index:\n",
    "        col_name = col[:25] + '_' + sel.replace(' ','_')\n",
    "        new_cols.append(col_name)\n",
    "        if (sel == 'nan'):\n",
    "            out_df.loc[:,col_name] = select_na\n",
    "        else:\n",
    "            out_df.loc[:,col_name] = ~ select_na #df[col]\n",
    "            selected = df[col].dropna().str.split(';').copy() #.tolist()\n",
    "            # need to strip the nulls\n",
    "            out_df.loc[~select_na,col_name] = selected.apply(lambda x: sel in x)\n",
    "            out_df.loc[select_na,col_name] = np.nan\n",
    "\n",
    "    return out_df, new_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs, lang_cols = split_multiselect(df, 'LanguageWorkedWith')\n",
    "langsfuture, langfuture_cols = split_multiselect(df, 'LanguageDesireNextYear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65679, 94)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df.merge(langs, how='outer', left_index=True, right_index=True)\n",
    "df_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.029765983038718"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many languages do each respondent claim :  5!!!\n",
    "df_.loc[:,lang_cols].sum(axis = 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageWorkedWith_JavaScript               71.476423\n",
       "LanguageWorkedWith_HTML/CSS                 63.811873\n",
       "LanguageWorkedWith_SQL                      56.692398\n",
       "LanguageWorkedWith_Java                     40.116323\n",
       "LanguageWorkedWith_Python                   36.975289\n",
       "LanguageWorkedWith_Bash/Shell/PowerShell    36.838259\n",
       "LanguageWorkedWith_C#                       32.974010\n",
       "LanguageWorkedWith_PHP                      25.947411\n",
       "LanguageWorkedWith_TypeScript               25.175475\n",
       "LanguageWorkedWith_C++                      20.243914\n",
       "LanguageWorkedWith_C                        16.946056\n",
       "LanguageWorkedWith_Ruby                      9.018103\n",
       "LanguageWorkedWith_Go                        8.910002\n",
       "LanguageWorkedWith_Other(s):                 8.520227\n",
       "LanguageWorkedWith_Swift                     7.082934\n",
       "LanguageWorkedWith_Kotlin                    6.988535\n",
       "LanguageWorkedWith_Objective-C               5.504042\n",
       "LanguageWorkedWith_Assembly                  4.831072\n",
       "LanguageWorkedWith_VBA                       4.547877\n",
       "LanguageWorkedWith_Scala                     4.270771\n",
       "LanguageWorkedWith_R                         4.158102\n",
       "LanguageWorkedWith_Rust                      3.016185\n",
       "LanguageWorkedWith_Dart                      1.894061\n",
       "LanguageWorkedWith_Elixir                    1.620000\n",
       "LanguageWorkedWith_Clojure                   1.566711\n",
       "LanguageWorkedWith_F#                        1.152575\n",
       "LanguageWorkedWith_WebAssembly               1.134305\n",
       "LanguageWorkedWith_Erlang                    0.947030\n",
       "LanguageWorkedWith_nan                       0.616635\n",
       "dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent of developers languages... check NaN...should be nonzero 405/65679\n",
    "(100*df_.loc[:,lang_cols].sum().sort_values(ascending=False)/df_.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Environment \n",
    "\n",
    "`DevEnviron`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "devenv, devenv_cols = split_multiselect(df, 'DevEnviron')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    65679.000000\n",
       "mean         2.826946\n",
       "std          1.599255\n",
       "min          1.000000\n",
       "25%          2.000000\n",
       "50%          3.000000\n",
       "75%          4.000000\n",
       "max         22.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many environs do each respondent claim :  almost 3!!!\n",
    "devenv.sum(axis = 1).describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JobFactor & WorkChallenges \n",
    "\n",
    "`JobFactors`,`WorkChallenge` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jobfact, jobfact_cols = split_multiselect(df, 'JobFactors')\n",
    "jobchal, jobchal_cols = split_multiselect(df, 'WorkChallenge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISC - containers, dababases, and misc tech\n",
    "\n",
    "`Containers`\n",
    "      `DatabaseWorkedWith`,`DatabaseDesireNextYear`, \n",
    "     `MiscTechWorkedWith`,`MiscTechDesireNextYear`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers, containers_cols = split_multiselect(df, 'Containers')\n",
    "database, database_cols = split_multiselect(df, 'DatabaseWorkedWith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "misctech, misctech_cols = split_multiselect(df, 'MiscTechWorkedWith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Respondent\n",
       "4        1.0\n",
       "5        3.0\n",
       "7        3.0\n",
       "9        3.0\n",
       "10       1.0\n",
       "13       3.0\n",
       "14       2.0\n",
       "16       3.0\n",
       "17       3.0\n",
       "19       3.0\n",
       "22       3.0\n",
       "23       3.0\n",
       "24       3.0\n",
       "25       1.0\n",
       "26       3.0\n",
       "28       1.0\n",
       "29       3.0\n",
       "30       2.0\n",
       "32       2.0\n",
       "33       3.0\n",
       "35       3.0\n",
       "36       2.0\n",
       "38       3.0\n",
       "39       3.0\n",
       "41       3.0\n",
       "42       3.0\n",
       "43       3.0\n",
       "44       3.0\n",
       "46       3.0\n",
       "47       3.0\n",
       "        ... \n",
       "88844    2.0\n",
       "88845    2.0\n",
       "88846    3.0\n",
       "88847    3.0\n",
       "88848    3.0\n",
       "88850    2.0\n",
       "88852    3.0\n",
       "88853    3.0\n",
       "88854    3.0\n",
       "88855    3.0\n",
       "88856    1.0\n",
       "88857    3.0\n",
       "88858    3.0\n",
       "88860    3.0\n",
       "88865    3.0\n",
       "88866    3.0\n",
       "88867    3.0\n",
       "88868    3.0\n",
       "88869    3.0\n",
       "88871    3.0\n",
       "88872    3.0\n",
       "88873    1.0\n",
       "88874    2.0\n",
       "88876    3.0\n",
       "88877    2.0\n",
       "88878    2.0\n",
       "88879    3.0\n",
       "88881    2.0\n",
       "88882    3.0\n",
       "88883    3.0\n",
       "Length: 65679, dtype: float64"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobchal.sum(axis=1)\n",
    "jobchal.WorkChallenge_nan.sum()\n",
    "jobchal[0:end-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(['Total day calls', 'Total eve calls', 'Total night calls'],\n",
    "               ['Area code'], aggfunc='mean')\n",
    "\n",
    "pd.crosstab(df['Churn'], df['Voice mail plan'], normalize=True)\n",
    "\n",
    "\n",
    "# Plotting a bar graph of the number of stores in each city, for the first ten cities listed\n",
    "# in the column 'City'\n",
    "city_count  = df['City'].value_counts()\n",
    "city_count = city_count[:10,]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(city_count.index, city_count.values, alpha=0.8)\n",
    "plt.title('Starbucks in top 10 cities in the World')\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('city', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "dont \n",
    "\n",
    "---\n",
    "\n",
    "go \n",
    "\n",
    "---\n",
    "\n",
    "below\n",
    "\n",
    "---\n",
    "\n",
    "here\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## CODE SNIPPITS for further analysis\n",
    "\n",
    "\n",
    "### advice from Matt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # these are some notes from matt on now to figure some things out...\n",
    "\n",
    "    df.loc[df['column'].isin(['value_1', 'value_2']), 'other_column']\n",
    "\n",
    "    if (value == value):  # Won't return true for nans (edited) \n",
    "        x = np.nan\n",
    "\n",
    "\n",
    "# Look at descriptive statistics for data (ignore Respondent since this is just an ID field)\n",
    "#survey.drop(['Respondent'], axis = 1).describe()\n",
    "\n",
    "### Dummies\n",
    "\n",
    "#METHOD 1\n",
    "# create the 'Sex_male' dummy variable using the 'map' method\n",
    "train['Sex_male'] = train.Sex.map({'female':0, 'male':1})\n",
    "train.head()\n",
    "\n",
    "# alternative: use 'get_dummies' to create one column for every possible value\n",
    "pd.get_dummies(train.Sex).head()\n",
    "\n",
    "# METHOD 2\n",
    "# drop the first dummy variable ('female') using the 'iloc' method\n",
    "pd.get_dummies(train.Sex).iloc[:, 1:].head()\n",
    "\n",
    "# drop the first dummy variable ('female') using the 'iloc' method\n",
    "pd.get_dummies(train.Sex).iloc[:, 1:].head()\n",
    "\n",
    "# add a prefix to identify the source of the dummy variables\n",
    "pd.get_dummies(train.Sex, prefix='Sex').iloc[:, 1:].head()\n",
    "\n",
    "# use 'get_dummies' with a feature that has 3 possible values\n",
    "pd.get_dummies(train.Embarked, prefix='Embarked').head(10)\n",
    "\n",
    "\n",
    "# drop the first dummy variable ('C')\n",
    "pd.get_dummies(train.Embarked, prefix='Embarked').iloc[:, 1:].head(10)\n",
    "\n",
    "# save the DataFrame of dummy variables and concatenate them to the original DataFrame\n",
    "embarked_dummies = pd.get_dummies(train.Embarked, prefix='Embarked').iloc[:, 1:]\n",
    "train = pd.concat([train, embarked_dummies], axis=1)\n",
    "train.head()\n",
    "\n",
    "# reset the DataFrame\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "train.head()\n",
    "\n",
    "\n",
    "# pass the DataFrame to 'get_dummies' and specify which columns to dummy (it drops the original columns)\n",
    "pd.get_dummies(train, columns=['Sex', 'Embarked']).head()\n",
    "                                            \n",
    "                                            \n",
    "pd.get_dummies(train,columns=['Sex','Embarked'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split_list code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent</th>\n",
       "      <th>LanguageWorkedWith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>VBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>Bash/Shell/PowerShell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>WebAssembly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>Other(s):</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329915</th>\n",
       "      <td>88877</td>\n",
       "      <td>Clojure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329916</th>\n",
       "      <td>88877</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329917</th>\n",
       "      <td>88877</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329918</th>\n",
       "      <td>88877</td>\n",
       "      <td>Scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329919</th>\n",
       "      <td>88877</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329920</th>\n",
       "      <td>88877</td>\n",
       "      <td>Other(s):</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329921</th>\n",
       "      <td>88878</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329922</th>\n",
       "      <td>88878</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329923</th>\n",
       "      <td>88878</td>\n",
       "      <td>Scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329924</th>\n",
       "      <td>88878</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329925</th>\n",
       "      <td>88879</td>\n",
       "      <td>Bash/Shell/PowerShell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329926</th>\n",
       "      <td>88879</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329927</th>\n",
       "      <td>88879</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329928</th>\n",
       "      <td>88881</td>\n",
       "      <td>Bash/Shell/PowerShell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329929</th>\n",
       "      <td>88881</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329930</th>\n",
       "      <td>88881</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329931</th>\n",
       "      <td>88881</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329932</th>\n",
       "      <td>88881</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329933</th>\n",
       "      <td>88881</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329934</th>\n",
       "      <td>88882</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329935</th>\n",
       "      <td>88882</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329936</th>\n",
       "      <td>88882</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329937</th>\n",
       "      <td>88882</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329938</th>\n",
       "      <td>88882</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329939</th>\n",
       "      <td>88882</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329940</th>\n",
       "      <td>88883</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329941</th>\n",
       "      <td>88883</td>\n",
       "      <td>HTML/CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329942</th>\n",
       "      <td>88883</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329943</th>\n",
       "      <td>88883</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329944</th>\n",
       "      <td>88883</td>\n",
       "      <td>Other(s):</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329945 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Respondent     LanguageWorkedWith\n",
       "0                4                      C\n",
       "1                4                    C++\n",
       "2                4                     C#\n",
       "3                4                 Python\n",
       "4                4                    SQL\n",
       "5                5                    C++\n",
       "6                5               HTML/CSS\n",
       "7                5                   Java\n",
       "8                5             JavaScript\n",
       "9                5                 Python\n",
       "10               5                    SQL\n",
       "11               5                    VBA\n",
       "12               7               HTML/CSS\n",
       "13               7             JavaScript\n",
       "14               9  Bash/Shell/PowerShell\n",
       "15               9                     C#\n",
       "16               9               HTML/CSS\n",
       "17               9             JavaScript\n",
       "18               9                 Python\n",
       "19               9                   Ruby\n",
       "20               9                   Rust\n",
       "21               9                    SQL\n",
       "22               9             TypeScript\n",
       "23               9            WebAssembly\n",
       "24               9              Other(s):\n",
       "25              10                     C#\n",
       "26              10                     Go\n",
       "27              10             JavaScript\n",
       "28              10                 Python\n",
       "29              10                      R\n",
       "...            ...                    ...\n",
       "329915       88877                Clojure\n",
       "329916       88877               HTML/CSS\n",
       "329917       88877                   Java\n",
       "329918       88877                  Scala\n",
       "329919       88877                  Swift\n",
       "329920       88877              Other(s):\n",
       "329921       88878               HTML/CSS\n",
       "329922       88878             JavaScript\n",
       "329923       88878                  Scala\n",
       "329924       88878             TypeScript\n",
       "329925       88879  Bash/Shell/PowerShell\n",
       "329926       88879                    C++\n",
       "329927       88879                 Python\n",
       "329928       88881  Bash/Shell/PowerShell\n",
       "329929       88881                     Go\n",
       "329930       88881               HTML/CSS\n",
       "329931       88881                   Java\n",
       "329932       88881             JavaScript\n",
       "329933       88881                 Python\n",
       "329934       88882                     C#\n",
       "329935       88882               HTML/CSS\n",
       "329936       88882                   Java\n",
       "329937       88882             JavaScript\n",
       "329938       88882                    PHP\n",
       "329939       88882                 Python\n",
       "329940       88883                     Go\n",
       "329941       88883               HTML/CSS\n",
       "329942       88883                   Java\n",
       "329943       88883             JavaScript\n",
       "329944       88883              Other(s):\n",
       "\n",
       "[329945 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create dataframe containing split string values by respondent number\n",
    "# more efficient than expanding along bool columns for each language\n",
    "def split_list(df, col):\n",
    "    \"\"\"Create a new dataframe that splits the values of multi-selection column col into individual selections and \n",
    "    places each selection value on a separate row. This new dataframe can be linked back to the original dataframe by \n",
    "    Respondent value.\n",
    "    \n",
    "    Args:\n",
    "    df: dataframe. Dataframe containing the multi-selection field col.\n",
    "       \n",
    "    Returns:\n",
    "    out_df: dataframe. New dataframe giving split values of col.\n",
    "    \"\"\"\n",
    "    \n",
    "    in_res = list(df.index)\n",
    "    in_list = list(df[col])\n",
    "    \n",
    "    out_res = []\n",
    "    out_list = []\n",
    "    \n",
    "    for i in range(len(in_list)):\n",
    "        if pd.isnull(in_list[i]) == False:\n",
    "            vals = in_list[i].split(';')\n",
    "            res = [in_res[i]]*len(vals)\n",
    "            \n",
    "            out_list.append(vals)\n",
    "            out_res.append(res)\n",
    "    \n",
    "    out_df = pd.DataFrame({'Respondent': list(np.concatenate(out_res)), col: list(np.concatenate(out_list))})\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "split_list(survey,'LanguageWorkedWith')\n",
    "#survey.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "695.556px",
    "left": "82.2432px",
    "top": "109.722px",
    "width": "317.535px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "621.997px",
    "left": "1120px",
    "right": "20px",
    "top": "119px",
    "width": "680.764px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
